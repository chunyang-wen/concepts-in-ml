# Common model architecture and paper

+ TOC
{:toc}

## Wide and deep

+ [Wide and Deep, CH](https://zhuanlan.zhihu.com/p/54464005)
+ [Wide and Deep, CH](https://zhuanlan.zhihu.com/p/43328492)
+ [Wide and Deep, ENG](https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html)
+ [Paper](https://arxiv.org/pdf/1606.07792.pdf)

![WND](/images/wide-and-deep.jpg)

## MMOE

+ [MMOE, CH](https://zhuanlan.zhihu.com/p/55752344)
+ [Paper](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007)

![MMOE](/images/mmoe.jpg)

## ESMM

+ [ESMM, CH](https://github.com/alibaba/x-deeplearning/wiki/%E5%85%A8%E7%A9%BA%E9%97%B4%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%A8%A1%E5%9E%8B(ESMM))
+ [Paper](https://arxiv.org/pdf/1804.07931.pdf)

![ESMM](/images/esmm.png)

## Transformer

+ [Transformer, ENG](http://jalammar.github.io/illustrated-transformer/)
+ [Paper](https://arxiv.org/abs/1706.03762)

![Transformer](/images/transformer.jpg)

## Sequence2Sequence

![BERT](/images/bert.jpg)

+ [The annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
+ [Bert](https://arxiv.org/pdf/1810.04805.pdf)
+ [Paper](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)
+ [知乎, CH](https://zhuanlan.zhihu.com/p/36030490)
+ [Transformer 知乎, CH](https://zhuanlan.zhihu.com/p/74723305)
+ [从 Word Embedding 到 BERT, CH](https://zhuanlan.zhihu.com/p/49271699)
+ [CSDN, CH](https://blog.csdn.net/dcrmg/article/details/80327069)


<img src="https://page-counter.glitch.me/pixel.svg" />
